{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform EDA and analysis\n",
    "**program:** 08_nb_mod_h100 <br>\n",
    "**author:** chris chan<br>\n",
    "**date:** jan 27,2021<br>\n",
    "**desc:** use clean df for analysis <br>\n",
    "\n",
    "**datasources:**<br>\n",
    "- sb_analytic (balanced df thru 2010)\n",
    "- billboard analytic (hot 100 thru 2019)\n",
    "- spotify random (random thru 2020)\n",
    "\n",
    "**articles**<br>\n",
    "https://towardsdatascience.com/understanding-bayes-theorem-7e31b8434d4b![image.png](attachment:image.png)\n",
    "https://towardsdatascience.com/understanding-the-naive-bayes-classifier-16b6ee03ff7b![image-2.png](attachment:image-2.png)\n",
    "\n",
    "**log reg workflow (kf cv)**<br>\n",
    "1. split 2 times (train,val,test)\n",
    "2. select features / label\n",
    "3. standardize if necessary\n",
    "4. define a kfold split object\n",
    "5. instantiate your model\n",
    "6. cross val score: apply 4,5. fit the model\n",
    "7. cross val predict: apply 4,5. get predicted vals on training set\n",
    "8. get scores: based on 6, define the score you want (if not accuracy). Also get classification report (f1,precision, etc.)\n",
    "9. confusion matrix: apply 7. based on training set\n",
    "10. AUC/ROC: apply to validation set to evaluate model\n",
    "\n",
    "a. may need to tune hyperparms by using gridsearchcv. find teh best estimator and place into object<br>\n",
    "b. refit model using best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "sns.set(context='notebook', style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Bring in data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpotifyID</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>loudness</th>\n",
       "      <th>is_hit</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285pBltuF7vW8TeWk8hdRR</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.566</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.218</td>\n",
       "      <td>83.903</td>\n",
       "      <td>239836</td>\n",
       "      <td>-7.230</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7dt6x5M1jzdTEt8oCbisTK</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.578</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.341</td>\n",
       "      <td>145.038</td>\n",
       "      <td>231267</td>\n",
       "      <td>-5.804</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78QR3Wp35dqAhFEc2qAGjE</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.389</td>\n",
       "      <td>112.511</td>\n",
       "      <td>145543</td>\n",
       "      <td>-6.903</td>\n",
       "      <td>1</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SpotifyID  danceability  energy  key  mode  speechiness  \\\n",
       "0  285pBltuF7vW8TeWk8hdRR         0.511   0.566    6     0        0.200   \n",
       "1  7dt6x5M1jzdTEt8oCbisTK         0.680   0.578   10     1        0.040   \n",
       "2  78QR3Wp35dqAhFEc2qAGjE         0.897   0.662    1     0        0.292   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0        0.3490               0.0     0.340    0.218   83.903       239836   \n",
       "1        0.3310               0.0     0.135    0.341  145.038       231267   \n",
       "2        0.0852               0.0     0.534    0.389  112.511       145543   \n",
       "\n",
       "   loudness  is_hit    year  \n",
       "0    -7.230       1  2018.0  \n",
       "1    -5.804       1  2018.0  \n",
       "2    -6.903       1  2019.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbdf=pd.read_csv(r'../data/clean/sbdf_clean.csv')\n",
    "sbdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create Label**\n",
    "- this LR mod is based on 1980 or not (using 1960+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf['in80']=np.where( (sbdf['year'] >= 1980) & (sbdf['year']<1990),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove rows below 1960**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf = sbdf[sbdf['year'] >= 1960] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13944\n",
       "1       91\n",
       "Name: in80, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbdf.in80.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf.columns = map(str.lower, sbdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf['decade'] = (sbdf.year//10*10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000    6239\n",
       "1990    3864\n",
       "2010    3829\n",
       "1980      91\n",
       "1960       8\n",
       "1970       4\n",
       "Name: decade, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbdf.decade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf = sbdf[sbdf['decade'] >= 1990] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf['track_seconds'] = sbdf['duration_ms'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['spotifyid', 'danceability', 'energy', 'key', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'duration_ms', 'loudness', 'is_hit', 'year', 'in80', 'decade',\n",
       "       'track_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. SPlit Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split first to remove test data\n",
    "df_train_st, df_test_st = train_test_split(sbdf, test_size=0.2, random_state=42 ) #, stratify=y)\n",
    "\n",
    "# SPlit again between train and val\n",
    "df_train, df_test = train_test_split(df_train_st, test_size=0.2, random_state=42 ) #, stratify=y)\n",
    "\n",
    "#df_train, df_test = train_test_split(bbdf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['acousticness','danceability','energy','loudness','valence','track_seconds']\n",
    "labels = ['is_hit']        \n",
    "\n",
    "#X_train = scaler.fit_transform(df_train[features])\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[labels]\n",
    "\n",
    "X_test = df_test[features]\n",
    "y_test = df_test['is_hit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T15:40:02.176530Z",
     "start_time": "2018-05-04T15:40:02.165476Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74069089277703"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cc : gaussion things are dist normally** <br>\n",
    "prob of A or prob B - its not jsut one number. we're defining the prob by a distribution. and teh distributino is defined by mean and variance<br>\n",
    "naieve: stores the mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T15:37:59.338534Z",
     "start_time": "2018-05-04T15:37:59.331014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.39291206e-01,  5.46869737e-01,  6.04790264e-01,\n",
       "        -9.53051945e+00,  5.22894797e-01,  2.37826734e+02],\n",
       "       [ 1.63936673e-01,  6.33707749e-01,  6.83965996e-01,\n",
       "        -6.64590886e+00,  5.29513764e-01,  2.39467431e+02]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.theta_ # mean of each feature by classa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T15:38:14.021429Z",
     "start_time": "2018-05-04T15:38:14.012671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.34725813,   0.18326361,   0.2588906 ,   5.01988968,\n",
       "          0.2684577 , 105.14615866],\n",
       "       [  0.20589302,   0.14647408,   0.17679807,   2.69539537,\n",
       "          0.22804138,  49.20262011]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(nb.sigma_) # variance of each feature by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00441465]),\n",
       " 'std_fit_time': array([0.00072407]),\n",
       " 'mean_score_time': array([0.00212817]),\n",
       " 'std_score_time': array([0.00023482]),\n",
       " 'params': [{}],\n",
       " 'split0_test_score': array([0.7382287]),\n",
       " 'split1_test_score': array([0.74088615]),\n",
       " 'split2_test_score': array([0.7296691]),\n",
       " 'split3_test_score': array([0.72854739]),\n",
       " 'split4_test_score': array([0.7296691]),\n",
       " 'mean_test_score': array([0.73340009]),\n",
       " 'std_test_score': array([0.00511363]),\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_train_score': array([0.732894]),\n",
       " 'split1_train_score': array([0.729707]),\n",
       " 'split2_train_score': array([0.73489415]),\n",
       " 'split3_train_score': array([0.73419319]),\n",
       " 'split4_train_score': array([0.73517454]),\n",
       " 'mean_train_score': array([0.73337258]),\n",
       " 'std_train_score': array([0.00199505])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "params = {}\n",
    "nb = GaussianNB()\n",
    "gs = GridSearchCV(nb, cv=skf, param_grid=params, return_train_score=True)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74069089277703"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74069089277703"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['priors', 'var_smoothing'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter alpha for estimator GaussianNB(). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-158c8750f576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 raise ValueError('Invalid parameter %s for estimator %s. '\n\u001b[0m\u001b[1;32m    250\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter alpha for estimator GaussianNB(). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "gs.param_grid = {'alpha': [0.1, .01]}\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00441465]),\n",
       " 'std_fit_time': array([0.00072407]),\n",
       " 'mean_score_time': array([0.00212817]),\n",
       " 'std_score_time': array([0.00023482]),\n",
       " 'params': [{}],\n",
       " 'split0_test_score': array([0.7382287]),\n",
       " 'split1_test_score': array([0.74088615]),\n",
       " 'split2_test_score': array([0.7296691]),\n",
       " 'split3_test_score': array([0.72854739]),\n",
       " 'split4_test_score': array([0.7296691]),\n",
       " 'mean_test_score': array([0.73340009]),\n",
       " 'std_test_score': array([0.00511363]),\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_train_score': array([0.732894]),\n",
       " 'split1_train_score': array([0.729707]),\n",
       " 'split2_train_score': array([0.73489415]),\n",
       " 'split3_train_score': array([0.73419319]),\n",
       " 'split4_train_score': array([0.73517454]),\n",
       " 'mean_train_score': array([0.73337258]),\n",
       " 'std_train_score': array([0.00199505])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian(lb, ub, mean=0, std=1, n=200, axis=0, mult=300, add=50):\n",
    "    '''\n",
    "    Draw a Gaussian curve on one of the axes, given a lower-bound (lb) and upper-bound (ub)\n",
    "    '''\n",
    "    x = np.linspace(lb, ub, n)\n",
    "    pdf = st.norm.pdf(x, loc=mean, scale=std)\n",
    "    \n",
    "    if axis == 0:\n",
    "        plt.plot(x, pdf * mult + add)\n",
    "    else:\n",
    "        plt.plot(pdf * mult + add, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of list vectors must match length of `data` when both are used, but `data` has length 2229 and the vector passed to `y` has length 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-33df14a6f674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwrong_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'energy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrugplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrong_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'energy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36mscatterplot\u001b[0;34m(x, y, hue, style, size, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, x_bins, y_bins, units, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ScatterPlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m     p = _ScatterPlotter(\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mx_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_bins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/seaborn/relational.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables, x_bins, y_bins, estimator, ci, n_boot, alpha, x_jitter, y_jitter, legend)\u001b[0m\n\u001b[1;32m    578\u001b[0m         )\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                             \u001b[0;34mf\" and the vector passed to `{key}` has length {len(val)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                         )\n\u001b[0;32m--> 902\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0mplot_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of list vectors must match length of `data` when both are used, but `data` has length 2229 and the vector passed to `y` has length 1."
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"362.131812pt\" version=\"1.1\" viewBox=\"0 0 548.121312 362.131812\" width=\"548.121312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-02-03T12:03:39.368769</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 362.131812 \n",
       "L 548.121312 362.131812 \n",
       "L 548.121312 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 38.721313 333.36 \n",
       "L 540.921312 333.36 \n",
       "L 540.921312 7.2 \n",
       "L 38.721313 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 61.548584 333.36 \n",
       "L 61.548584 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(57.878366 352.308312)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.15625 35.296875 \n",
       "Q 4.15625 48 6.765625 55.734375 \n",
       "Q 9.375 63.484375 14.515625 67.671875 \n",
       "Q 19.671875 71.875 27.484375 71.875 \n",
       "Q 33.25 71.875 37.59375 69.546875 \n",
       "Q 41.9375 67.234375 44.765625 62.859375 \n",
       "Q 47.609375 58.5 49.21875 52.21875 \n",
       "Q 50.828125 45.953125 50.828125 35.296875 \n",
       "Q 50.828125 22.703125 48.234375 14.96875 \n",
       "Q 45.65625 7.234375 40.5 3 \n",
       "Q 35.359375 -1.21875 27.484375 -1.21875 \n",
       "Q 17.140625 -1.21875 11.234375 6.203125 \n",
       "Q 4.15625 15.140625 4.15625 35.296875 \n",
       "z\n",
       "M 13.1875 35.296875 \n",
       "Q 13.1875 17.671875 17.3125 11.828125 \n",
       "Q 21.4375 6 27.484375 6 \n",
       "Q 33.546875 6 37.671875 11.859375 \n",
       "Q 41.796875 17.71875 41.796875 35.296875 \n",
       "Q 41.796875 52.984375 37.671875 58.78125 \n",
       "Q 33.546875 64.59375 27.390625 64.59375 \n",
       "Q 21.34375 64.59375 17.71875 59.46875 \n",
       "Q 13.1875 52.9375 13.1875 35.296875 \n",
       "z\n",
       "\" id=\"ArialMT-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 166.85506 333.36 \n",
       "L 166.85506 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(155.844404 352.308312)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 50.34375 8.453125 \n",
       "L 50.34375 0 \n",
       "L 3.03125 0 \n",
       "Q 2.9375 3.171875 4.046875 6.109375 \n",
       "Q 5.859375 10.9375 9.828125 15.625 \n",
       "Q 13.8125 20.3125 21.34375 26.46875 \n",
       "Q 33.015625 36.03125 37.109375 41.625 \n",
       "Q 41.21875 47.21875 41.21875 52.203125 \n",
       "Q 41.21875 57.421875 37.46875 61 \n",
       "Q 33.734375 64.59375 27.734375 64.59375 \n",
       "Q 21.390625 64.59375 17.578125 60.78125 \n",
       "Q 13.765625 56.984375 13.71875 50.25 \n",
       "L 4.6875 51.171875 \n",
       "Q 5.609375 61.28125 11.65625 66.578125 \n",
       "Q 17.71875 71.875 27.9375 71.875 \n",
       "Q 38.234375 71.875 44.234375 66.15625 \n",
       "Q 50.25 60.453125 50.25 52 \n",
       "Q 50.25 47.703125 48.484375 43.546875 \n",
       "Q 46.734375 39.40625 42.65625 34.8125 \n",
       "Q 38.578125 30.21875 29.109375 22.21875 \n",
       "Q 21.1875 15.578125 18.9375 13.203125 \n",
       "Q 16.703125 10.84375 15.234375 8.453125 \n",
       "z\n",
       "\" id=\"ArialMT-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 272.161536 333.36 \n",
       "L 272.161536 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(261.15088 352.308312)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 32.328125 0 \n",
       "L 32.328125 17.140625 \n",
       "L 1.265625 17.140625 \n",
       "L 1.265625 25.203125 \n",
       "L 33.9375 71.578125 \n",
       "L 41.109375 71.578125 \n",
       "L 41.109375 25.203125 \n",
       "L 50.78125 25.203125 \n",
       "L 50.78125 17.140625 \n",
       "L 41.109375 17.140625 \n",
       "L 41.109375 0 \n",
       "z\n",
       "M 32.328125 25.203125 \n",
       "L 32.328125 57.46875 \n",
       "L 9.90625 25.203125 \n",
       "z\n",
       "\" id=\"ArialMT-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-52\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 377.468012 333.36 \n",
       "L 377.468012 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(366.457356 352.308312)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 49.75 54.046875 \n",
       "L 41.015625 53.375 \n",
       "Q 39.84375 58.546875 37.703125 60.890625 \n",
       "Q 34.125 64.65625 28.90625 64.65625 \n",
       "Q 24.703125 64.65625 21.53125 62.3125 \n",
       "Q 17.390625 59.28125 14.984375 53.46875 \n",
       "Q 12.59375 47.65625 12.5 36.921875 \n",
       "Q 15.671875 41.75 20.265625 44.09375 \n",
       "Q 24.859375 46.4375 29.890625 46.4375 \n",
       "Q 38.671875 46.4375 44.84375 39.96875 \n",
       "Q 51.03125 33.5 51.03125 23.25 \n",
       "Q 51.03125 16.5 48.125 10.71875 \n",
       "Q 45.21875 4.9375 40.140625 1.859375 \n",
       "Q 35.0625 -1.21875 28.609375 -1.21875 \n",
       "Q 17.625 -1.21875 10.6875 6.859375 \n",
       "Q 3.765625 14.9375 3.765625 33.5 \n",
       "Q 3.765625 54.25 11.421875 63.671875 \n",
       "Q 18.109375 71.875 29.4375 71.875 \n",
       "Q 37.890625 71.875 43.28125 67.140625 \n",
       "Q 48.6875 62.40625 49.75 54.046875 \n",
       "z\n",
       "M 13.875 23.1875 \n",
       "Q 13.875 18.65625 15.796875 14.5 \n",
       "Q 17.71875 10.359375 21.1875 8.171875 \n",
       "Q 24.65625 6 28.46875 6 \n",
       "Q 34.03125 6 38.03125 10.484375 \n",
       "Q 42.046875 14.984375 42.046875 22.703125 \n",
       "Q 42.046875 30.125 38.078125 34.390625 \n",
       "Q 34.125 38.671875 28.125 38.671875 \n",
       "Q 22.171875 38.671875 18.015625 34.390625 \n",
       "Q 13.875 30.125 13.875 23.1875 \n",
       "z\n",
       "\" id=\"ArialMT-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-54\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 482.774488 333.36 \n",
       "L 482.774488 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(471.763832 352.308312)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 17.671875 38.8125 \n",
       "Q 12.203125 40.828125 9.5625 44.53125 \n",
       "Q 6.9375 48.25 6.9375 53.421875 \n",
       "Q 6.9375 61.234375 12.546875 66.546875 \n",
       "Q 18.171875 71.875 27.484375 71.875 \n",
       "Q 36.859375 71.875 42.578125 66.421875 \n",
       "Q 48.296875 60.984375 48.296875 53.171875 \n",
       "Q 48.296875 48.1875 45.671875 44.5 \n",
       "Q 43.0625 40.828125 37.75 38.8125 \n",
       "Q 44.34375 36.671875 47.78125 31.875 \n",
       "Q 51.21875 27.09375 51.21875 20.453125 \n",
       "Q 51.21875 11.28125 44.71875 5.03125 \n",
       "Q 38.234375 -1.21875 27.640625 -1.21875 \n",
       "Q 17.046875 -1.21875 10.546875 5.046875 \n",
       "Q 4.046875 11.328125 4.046875 20.703125 \n",
       "Q 4.046875 27.6875 7.59375 32.390625 \n",
       "Q 11.140625 37.109375 17.671875 38.8125 \n",
       "z\n",
       "M 15.921875 53.71875 \n",
       "Q 15.921875 48.640625 19.1875 45.40625 \n",
       "Q 22.46875 42.1875 27.6875 42.1875 \n",
       "Q 32.765625 42.1875 36.015625 45.375 \n",
       "Q 39.265625 48.578125 39.265625 53.21875 \n",
       "Q 39.265625 58.0625 35.90625 61.359375 \n",
       "Q 32.5625 64.65625 27.59375 64.65625 \n",
       "Q 22.5625 64.65625 19.234375 61.421875 \n",
       "Q 15.921875 58.203125 15.921875 53.71875 \n",
       "z\n",
       "M 13.09375 20.65625 \n",
       "Q 13.09375 16.890625 14.875 13.375 \n",
       "Q 16.65625 9.859375 20.171875 7.921875 \n",
       "Q 23.6875 6 27.734375 6 \n",
       "Q 34.03125 6 38.125 10.046875 \n",
       "Q 42.234375 14.109375 42.234375 20.359375 \n",
       "Q 42.234375 26.703125 38.015625 30.859375 \n",
       "Q 33.796875 35.015625 27.4375 35.015625 \n",
       "Q 21.234375 35.015625 17.15625 30.90625 \n",
       "Q 13.09375 26.8125 13.09375 20.65625 \n",
       "z\n",
       "\" id=\"ArialMT-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-56\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 318.534545 \n",
       "L 540.921312 318.534545 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(21.880875 323.258702)scale(0.132 -0.132)\">\n",
       "       <use xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 271.564699 \n",
       "L 540.921312 271.564699 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 276.288855)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.25 0 \n",
       "L 28.46875 0 \n",
       "L 28.46875 56 \n",
       "Q 25.296875 52.984375 20.140625 49.953125 \n",
       "Q 14.984375 46.921875 10.890625 45.40625 \n",
       "L 10.890625 53.90625 \n",
       "Q 18.265625 57.375 23.78125 62.296875 \n",
       "Q 29.296875 67.234375 31.59375 71.875 \n",
       "L 37.25 71.875 \n",
       "z\n",
       "\" id=\"ArialMT-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 224.594852 \n",
       "L 540.921312 224.594852 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 229.319008)scale(0.132 -0.132)\">\n",
       "       <use xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 177.625005 \n",
       "L 540.921312 177.625005 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 182.349161)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.203125 18.890625 \n",
       "L 12.984375 20.0625 \n",
       "Q 14.5 12.59375 18.140625 9.296875 \n",
       "Q 21.78125 6 27 6 \n",
       "Q 33.203125 6 37.46875 10.296875 \n",
       "Q 41.75 14.59375 41.75 20.953125 \n",
       "Q 41.75 27 37.796875 30.921875 \n",
       "Q 33.84375 34.859375 27.734375 34.859375 \n",
       "Q 25.25 34.859375 21.53125 33.890625 \n",
       "L 22.515625 41.609375 \n",
       "Q 23.390625 41.5 23.921875 41.5 \n",
       "Q 29.546875 41.5 34.03125 44.421875 \n",
       "Q 38.53125 47.359375 38.53125 53.46875 \n",
       "Q 38.53125 58.296875 35.25 61.46875 \n",
       "Q 31.984375 64.65625 26.8125 64.65625 \n",
       "Q 21.6875 64.65625 18.265625 61.421875 \n",
       "Q 14.84375 58.203125 13.875 51.765625 \n",
       "L 5.078125 53.328125 \n",
       "Q 6.6875 62.15625 12.390625 67.015625 \n",
       "Q 18.109375 71.875 26.609375 71.875 \n",
       "Q 32.46875 71.875 37.390625 69.359375 \n",
       "Q 42.328125 66.84375 44.9375 62.5 \n",
       "Q 47.5625 58.15625 47.5625 53.265625 \n",
       "Q 47.5625 48.640625 45.0625 44.828125 \n",
       "Q 42.578125 41.015625 37.703125 38.765625 \n",
       "Q 44.046875 37.3125 47.5625 32.6875 \n",
       "Q 51.078125 28.078125 51.078125 21.140625 \n",
       "Q 51.078125 11.765625 44.234375 5.25 \n",
       "Q 37.40625 -1.265625 26.953125 -1.265625 \n",
       "Q 17.53125 -1.265625 11.296875 4.34375 \n",
       "Q 5.078125 9.96875 4.203125 18.890625 \n",
       "z\n",
       "\" id=\"ArialMT-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-51\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 130.655158 \n",
       "L 540.921312 130.655158 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 400 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 135.379314)scale(0.132 -0.132)\">\n",
       "       <use xlink:href=\"#ArialMT-52\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 83.685311 \n",
       "L 540.921312 83.685311 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 500 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 88.409467)scale(0.132 -0.132)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.15625 18.75 \n",
       "L 13.375 19.53125 \n",
       "Q 14.40625 12.796875 18.140625 9.390625 \n",
       "Q 21.875 6 27.15625 6 \n",
       "Q 33.5 6 37.890625 10.78125 \n",
       "Q 42.28125 15.578125 42.28125 23.484375 \n",
       "Q 42.28125 31 38.0625 35.34375 \n",
       "Q 33.84375 39.703125 27 39.703125 \n",
       "Q 22.75 39.703125 19.328125 37.765625 \n",
       "Q 15.921875 35.84375 13.96875 32.765625 \n",
       "L 5.71875 33.84375 \n",
       "L 12.640625 70.609375 \n",
       "L 48.25 70.609375 \n",
       "L 48.25 62.203125 \n",
       "L 19.671875 62.203125 \n",
       "L 15.828125 42.96875 \n",
       "Q 22.265625 47.46875 29.34375 47.46875 \n",
       "Q 38.71875 47.46875 45.15625 40.96875 \n",
       "Q 51.609375 34.46875 51.609375 24.265625 \n",
       "Q 51.609375 14.546875 45.953125 7.46875 \n",
       "Q 39.0625 -1.21875 27.15625 -1.21875 \n",
       "Q 17.390625 -1.21875 11.203125 4.25 \n",
       "Q 5.03125 9.71875 4.15625 18.75 \n",
       "z\n",
       "\" id=\"ArialMT-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-53\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path clip-path=\"url(#p14174b3db1)\" d=\"M 38.721313 36.715464 \n",
       "L 540.921312 36.715464 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 600 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(7.2 41.43962)scale(0.132 -0.132)\">\n",
       "       <use xlink:href=\"#ArialMT-54\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#p14174b3db1)\" d=\"M 61.548585 194.610623 \n",
       "L 61.727786 133.168557 \n",
       "L 61.76468 136.527691 \n",
       "L 61.870092 175.751011 \n",
       "L 62.073011 267.972527 \n",
       "L 62.073011 267.972527 \n",
       "\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#p14174b3db1)\" d=\"M 61.548585 96.189894 \n",
       "L 61.63555 22.025455 \n",
       "L 61.688256 53.16261 \n",
       "L 62.015034 294.465711 \n",
       "L 62.073011 294.972026 \n",
       "L 62.073011 294.972026 \n",
       "\" style=\"fill:none;stroke:#dd8452;stroke-linecap:round;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#p14174b3db1)\" d=\"M 91.881719 318.534545 \n",
       "L 116.576676 318.469515 \n",
       "L 271.044216 318.374291 \n",
       "L 431.713661 318.276745 \n",
       "L 369.580569 318.223327 \n",
       "L 107.870813 318.072362 \n",
       "L 107.870813 318.072362 \n",
       "\" style=\"fill:none;stroke:#55a868;stroke-linecap:round;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#p14174b3db1)\" d=\"M 87.912285 318.534545 \n",
       "L 88.30249 318.49274 \n",
       "L 92.064627 318.446289 \n",
       "L 123.401581 318.390549 \n",
       "L 352.906233 318.304615 \n",
       "L 518.09404 318.237262 \n",
       "L 399.068221 318.181521 \n",
       "L 112.522827 318.072362 \n",
       "L 112.522827 318.072362 \n",
       "\" style=\"fill:none;stroke:#c44e52;stroke-linecap:round;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 38.721313 333.36 \n",
       "L 38.721313 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 540.921312 333.36 \n",
       "L 540.921312 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 38.721313 333.36 \n",
       "L 540.921312 333.36 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 38.721313 7.2 \n",
       "L 540.921312 7.2 \n",
       "\" style=\"fill:none;stroke:#cccccc;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p14174b3db1\">\n",
       "   <rect height=\"326.16\" width=\"502.2\" x=\"38.721313\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feature in range(2):\n",
    "    for gender in range(2):\n",
    "        plot_gaussian(X_test.iloc[:, feature].min(), \n",
    "                      X_test.iloc[:, feature].max(), \n",
    "                      nb.theta_[gender][feature],  # See above\n",
    "                      np.sqrt(nb.sigma_)[gender][feature],  # See above\n",
    "                      axis=feature)\n",
    "        \n",
    "preds = nb.predict(X_test)\n",
    "wrong_mask = y_test != preds\n",
    "\n",
    "sns.scatterplot(data=X_test, x=df_test['energy'], y= labels, hue=preds, s=10)\n",
    "sns.rugplot(data=X_test[wrong_mask], x=df_test['energy'], y=labels, hue=y_test, legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cc the likelinhoood is probabily of height x and wegith y (hight 60 or weight 120) given that gender is M or F** <br>\n",
    "very important graph<br>\n",
    "wg=120<br>\n",
    "ht60<br>\n",
    "given that its' male - so both are low<br>\n",
    "given that's ifemail<br>\n",
    "ht60<br>\n",
    "wg 120<br>\n",
    "maximize the likelyhood - what's bigger on the distribution<br>\n",
    "and do that on the other ones<br>\n",
    "once you have the distributions set<br>\n",
    "\n",
    "\n",
    "**not very interpretable**\n",
    "- naive bayes: whats the avg for each class and std for each class\n",
    "- gradient boosting\n",
    "- neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to predict whether or not the song is a hit or not. For the sake of simplicity, we'll split the data once, between a train set and a test set. *Of course, in practice, you'll want to cross validate with multiple splits of the data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Full Model with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can incorporate more features using the sklearn Logistic Regression implemetation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. TRAINING: standardize your features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = ['energy','mode','acousticness','danceability','energy','loudness','key','instrumentalness']\n",
    "\n",
    "# Since we're using more than one feature, let's scale our features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(df_train[features])\n",
    "y_train = df_train['in80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. TRAINING: Fit a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_3 = LogisticRegression()  # We'll also regularize our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. TEST: standardize your features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(df_test[features])\n",
    "y_test = df_test['in80']\n",
    "\n",
    "preds = lm_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lm_3.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(true, probas):\n",
    "    auc = roc_auc_score(true, probas)\n",
    "\n",
    "    plt.plot(fpr, tpr, marker='o')\n",
    "    plt.xlabel('1 - Specificity (FPR)')\n",
    "    plt.ylabel('Sensitivity (TPR)');\n",
    "    plt.title(f\"Area Under the ROC Curve: {round(auc, 3)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(df_test['in80'], lm_3.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f. Precision and Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "\n",
    "# using the default threshold of 0.5, which is what vanilla predict does\n",
    "y_predict = lm_3.predict(X_test)\n",
    "print(\"Default threshold:\")\n",
    "print(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_test, y_predict), \n",
    "                                                     recall_score(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whenver my \"hit alarm (prediction)\" went off, how many times was it actually a hit?? 69%\n",
    "Whenever there was a true hit, how many times did i predict it to be a hit?? **\n",
    "\n",
    "- what's more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the new threshold of 0.06\n",
    "y_predict = (lm_3.predict_proba(X_test)[:,1] > 0.35)\n",
    "print(\"Threshold of 0.06:\")\n",
    "print(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_test, y_predict), \n",
    "                                                     recall_score(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If i'm prediction a lot more hits (by decreasing my threshold) I'm allowing more false positives - or DECREASING my precision. However I might INCREASE my recall because I've practially predicted all of the hits accordingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the probabilities to make a curve showing us how recall \n",
    "# and thresholds trade off \n",
    "\n",
    "precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_test, lm_3.predict_proba(X_test)[:,1] )\n",
    "\n",
    "plt.figure(dpi=80)\n",
    "plt.plot(threshold_curve, precision_curve[1:],label='precision')\n",
    "plt.plot(threshold_curve, recall_curve[1:], label='recall')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Threshold (above this probability, label as hit)');\n",
    "plt.title('Precision and Recall Curves');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=80)\n",
    "plt.plot(recall_curve[1:], precision_curve[1:],label='precision')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CC: F1 score** - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, its better to look at both Precision and Recall. In our case, F1 score is 0.701.\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g. F1 scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can just ask sklearn\n",
    "y_predict = lm_3.predict(X_test)\n",
    "f1_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the threshold of 0.06?\n",
    "y_predict = (lm_3.predict_proba(X_test)[:, 1] > 0.50)\n",
    "f1_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h. Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predict)\n",
    "#accuracy_score(y_test, y_predict, normalize=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**True Negatives are so high therefore accuracy is high**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ROC curve\n",
    "\n",
    "We've already seen that we don't have to accept a 50% threshold cutoff. As we've seen, we can plot our models with different thresholds on the same chart and get a ROC curve. This curve plots the *true positive rate* on the y axis, and the *false positive rate* on the x axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP/P = True positive rate\n",
    "# false positive rate = FP / true negatives = FP / (FP + TN) \n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lm_3.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr,lw=2)\n",
    "plt.plot([0,1],[0,1],c='violet',ls='--')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve for hits problem');\n",
    "print(\"ROC AUC score = \", roc_auc_score(y_test, lm_3.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-class Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model uses DECADE as the label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import datasets\n",
    "#digits = datasets.load_digits(n_class=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['acousticness','danceability','energy','loudness','valence','track_seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split first to remove test data\n",
    "df_train_st, df_test_st = train_test_split(bbdf, test_size=0.2, random_state=42 ) #, stratify=y)\n",
    "\n",
    "# SPlit again between train and val\n",
    "df_train, df_test = train_test_split(df_train_st, test_size=0.2, random_state=42 ) #, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick between classifying in two different ways:\n",
    "\n",
    "#### One vs. Rest (`ovr`)\n",
    "\n",
    "For each class (in this case, for each number) we will have a separate logistic regression model. Each one of these models assigns a probability for whether an observation is that class, or is \"one of the rest\". So:\n",
    "\n",
    "**Model 1:** Calculate $p_1 = P(y=1|x)$ where $y=1$ if the number is *one*, and $y=0$ otherwise\n",
    "\n",
    "**Model 2:** Calculate $p_2 = P(y=1|x)$ where $y=1$ if the number is *two*, and $y=0$ otherwise\n",
    "\n",
    "**Model 3:** Calculate $p_3 = P(y=1|x)$ where $y=1$ if the number is *three*, and $y=0$ otherwise\n",
    "\n",
    "... and so on. Then, **we make the classification by picking the highest $p_i$ among all these models**.\n",
    "\n",
    "#### Softmax (`multinomial`)\n",
    "\n",
    "This actually introduces a **new link function**. So, rather than use the traditional sigmoid function here, we use the \"softmax\" function:\n",
    "\n",
    "$$\n",
    "\\displaystyle \\sigma (\\mathbf {z} )_{i}={\\frac {e^{z_{i}}}{\\sum _{j=1}^{K}e^{z_{j}}}}{\\text{ for }}i=1,\\dotsc ,K{\\text{ and }}\\mathbf {z} =(z_{1},\\dotsc ,z_{K})\\in \\mathbb {R} ^{K}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, again we have $k$ different models, but now we're saying that for each model, use a special link function that actually incorporates some aspect of the other link functions:\n",
    "\n",
    "**Model 1:** Let $z_1 = \\beta_{10} + \\beta_{11}x_1 + \\dots + \\beta_{1k}x_k$ and use the sigmoid link function $\\sigma(\\mathbf{z})_1$\n",
    "\n",
    "**Model 2:** Let $z_2 = \\beta_{20} + \\beta_{21}x_1 + \\dots + \\beta_{2k}x_k$ and use the sigmoid link function $\\sigma(\\mathbf{z})_2$\n",
    "\n",
    "**Model 3:** Let $z_3 = \\beta_{30} + \\beta_{31}x_1 + \\dots + \\beta_{3k}x_k$ and use the sigmoid link function $\\sigma(\\mathbf{z})_3$\n",
    "\n",
    "... and so on. Notice that each model has its own set of coefficients $\\beta_j$ and each link function actually uses the sum of these linear combinations from all the other models. In doing so, **the multinomial method creates a probability distribution among the possible classes**. Then, we just pick the highest probability among this distribution. This is nice for many reasons, and we'll see later that the same concept is actually used in many other aspects of Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ovr = LogisticRegression(solver='newton-cg', multi_class='ovr')\n",
    "lm_mn = LogisticRegression(solver='newton-cg', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features]\n",
    "y_train = df_train['decade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ovr.fit(X_train, y_train)\n",
    "lm_mn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ovr = lm_ovr.predict(df_test[features])\n",
    "preds_mn = lm_mn.predict(df_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df_test['decade'],preds_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df_test['decade'], preds_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying a heatmap to show predictions - confusion matrix (on ovr)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [1960,1970,1980,1990,2000,2010]\n",
    "cm = confusion_matrix(df_test['decade'], preds_ovr, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier (one vs all)')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba_ovr = lm_ovr.predict_proba(df_test[features])\n",
    "preds_proba_mn = lm_mn.predict_proba(df_test[features])\n",
    "#preds_proba_mn = lm_mn.predict_proba(df_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_aucs(labels, scores, name='One-vs-Rest', kind='ovr'):\n",
    "    ohe = OneHotEncoder()\n",
    "    labels_ohe = ohe.fit_transform(labels)\n",
    "    labels_ohe = labels_ohe.toarray()\n",
    "    \n",
    "    print(f'Average: {roc_auc_score(labels_ohe, scores, multi_class=kind)}')\n",
    "    \n",
    "    auc_scores = roc_auc_score(labels_ohe, scores, multi_class=kind, average=None)\n",
    "    auc_scores = {i:s for i, s in enumerate(auc_scores)}\n",
    "    \n",
    "    return auc_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keep in mind these are AUC scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One-vs-Rest\\n\")\n",
    "\n",
    "get_multiclass_aucs(df_test[['decade']], preds_proba_ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multinomial\\n\")\n",
    "get_multiclass_aucs(df_test[['decade']], preds_proba_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**just get accuracy scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can just ask sklearn\n",
    "f1_score(y_test, preds_ovr,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h. Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,preds_ovr)\n",
    "#accuracy_score(y_test, y_predict, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split first to remove test data\n",
    "df_train_st, df_test_st = train_test_split(bbdf, test_size=0.2, random_state=42 ) #, stratify=y)\n",
    "\n",
    "# SPlit again between train and val\n",
    "df_train, df_test = train_test_split(df_train_st, test_size=0.2, random_state=42 ) #, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. scale your vars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['acousticness','danceability','energy','loudness','valence','track_seconds']\n",
    "\n",
    "# Since we're using more than one feature, let's scale our features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(df_train[features])\n",
    "y_train = df_train['decade']\n",
    "\n",
    "X_test = scaler.fit_transform(df_test[features])\n",
    "y_test = df_test['decade']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. fit model and get accuracy**<br>\n",
    "**BELOW we have 2 different ways of getting the same CV answers:**\n",
    "\n",
    "1. you can instantiate an skfold header OR do it directly in steps below\n",
    "2. you MUST instantiate your logistic regression\n",
    "3. generally speaking you want to assign your MODEL FIT to an object.<br>\n",
    ". you should probably ALWAYS do these 2 steps:<br>\n",
    "    . assign accuracy (during the fit)<br>\n",
    "    . assign predicted values (during the fit)<br>\n",
    ". to do a fit you can do the following:<br>\n",
    "    . model_selection.cross_val_score: this automatically gives you your accuracy scores<br>\n",
    "    . cross_val_predict: this will give you your predictors SO THAT you can compute your accuracy and other measures based on these PREDICTED values:<br>\n",
    "        . metrics.accuracy_score: will give you the accuracy score<br>\n",
    "        . metrics.classification_report: will give you precision/recall/f1/support/accuracy<br>\n",
    "<br>\n",
    ". Model 1 below seems to be more comprehensive and flexible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "#skfold = StratifiedKFold(n_splits=5, random_state=42)\n",
    "skfold = KFold(n_splits=5, random_state=42)\n",
    "model_skfold = LogisticRegression()\n",
    "#model_skfold = OneVsRestClassifier() \n",
    "#model_skfold = OneVsRestClassifier(LinearSVC(random_state=42)) \n",
    "# this fits the model and gets us an accuracy scores (only gets scores)\n",
    "\n",
    "# accuracy\n",
    "results_skfold = cross_val_score(model_skfold, X_train, y_train, cv=skfold)\n",
    "\n",
    "predict_skfold = cross_val_predict(model_skfold, X_train, y_train, cv=skfold)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))\n",
    "#print(metrics.accuracy_score(y_train,predict_skfold))\n",
    "print(metrics.classification_report(y_train,predict_skfold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUC: Trying on the TEST Data (to see if it matches with the results above where accuracy was near 80%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiclass_aucs(labels, scores, name='One-vs-Rest', kind='ovr'):\n",
    "    ohe = OneHotEncoder()\n",
    "    labels_ohe = ohe.fit_transform(labels)\n",
    "    labels_ohe = labels_ohe.toarray()\n",
    "    \n",
    "    print(f'Average: {roc_auc_score(labels_ohe, scores, multi_class=kind)}')\n",
    "    \n",
    "    auc_scores = roc_auc_score(labels_ohe, scores, multi_class=kind, average=None)\n",
    "    auc_scores = {i:s for i, s in enumerate(auc_scores)}\n",
    "    \n",
    "    return auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "\n",
    "print(\"One-vs-Rest\\n\")\n",
    "predict_proba_skfold = cross_val_predict(model_skfold, X_test, y_test, cv=skfold,method='predict_proba')\n",
    "get_multiclass_aucs(df_test[['decade']], predict_proba_skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**back to TRAINING DATA : based on PREDICTED you have your confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df_train['decade'], predict_skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [1960,1970,1980,1990,2000,2010]\n",
    "cm = confusion_matrix(df_train['decade'], predict_skfold, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING**\n",
    "- here we test one vs rest classifier using sklearn\n",
    "- we fit the model on train first\n",
    "- we use the coeffs on test and come up with predictors\n",
    "- somehow, only 3 years are being predicted from our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "df_test['decade']= (df_test['decade'].astype(int))\n",
    "df_train['decade'] = (df_train['decade'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[features]\n",
    "y_train = df_train['decade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "test_fit = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train)\n",
    "test_pred = test_fit.predict(df_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df_test['decade'], \n",
    "                 test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['decade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(test_pred, return_counts=True)\n",
    "freqs = np.asarray((unique, counts)).T\n",
    "\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "df_test['decade']= (df_test['decade'].astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [1960,1970,1980,1990,2000,2010]\n",
    "cm = confusion_matrix(df_test['decade'], test_pred, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
